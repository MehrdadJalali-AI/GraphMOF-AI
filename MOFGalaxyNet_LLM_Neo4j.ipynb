{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehrdadJalali-AI/GraphMOF-AI/blob/main/MOFGalaxyNet_LLM_Neo4j.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6HmMc_I8qkw"
      },
      "outputs": [],
      "source": [
        "!pip install neo4j torch torch_geometric networkx openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQKqQe0a8qkx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import openai\n",
        "from neo4j import GraphDatabase\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqdoRS6r8qky"
      },
      "outputs": [],
      "source": [
        "# Connect to Neo4j (Replace with your credentials)\n",
        "NEO4J_URI = \"bolt://localhost:7687\"\n",
        "USERNAME = \"neo4j\"\n",
        "PASSWORD = \"your_password\"\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(USERNAME, PASSWORD))\n",
        "\n",
        "# Function to create MOF Graph\n",
        "def create_mof_graph(tx):\n",
        "    mof_data = [\n",
        "        (\"MOF-5\", 0.8, 0.9),\n",
        "        (\"UiO-66\", 0.75, 0.95),\n",
        "        (\"HKUST-1\", 0.85, 0.8),\n",
        "        (\"MIL-101\", 0.9, 0.88),\n",
        "        (\"ZIF-8\", 0.7, 0.92)\n",
        "    ]\n",
        "\n",
        "    for mof, adsorption, stability in mof_data:\n",
        "        tx.run(\"\"\"\n",
        "        MERGE (m:MOF {name: $name})\n",
        "        SET m.adsorption = $adsorption, m.stability = $stability\n",
        "        \"\"\", name=mof, adsorption=adsorption, stability=stability)\n",
        "\n",
        "    edges = [(\"MOF-5\", \"UiO-66\"), (\"MOF-5\", \"HKUST-1\"), (\"HKUST-1\", \"MIL-101\"), (\"UiO-66\", \"ZIF-8\")]\n",
        "    for mof1, mof2 in edges:\n",
        "        tx.run(\"\"\"\n",
        "        MATCH (m1:MOF {name: $mof1}), (m2:MOF {name: $mof2})\n",
        "        MERGE (m1)-[:SIMILAR_TO]->(m2)\n",
        "        \"\"\", mof1=mof1, mof2=mof2)\n",
        "\n",
        "with driver.session() as session:\n",
        "    session.write_transaction(create_mof_graph)\n",
        "print(\"✅ MOF Graph Created in Neo4j!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyT5toLh8qkz"
      },
      "outputs": [],
      "source": [
        "def create_mof_networkx():\n",
        "    G = nx.Graph()\n",
        "    mof_nodes = [\"MOF-5\", \"UiO-66\", \"HKUST-1\", \"MIL-101\", \"ZIF-8\"]\n",
        "    for node in mof_nodes:\n",
        "        G.add_node(node, adsorption=torch.rand(1).item(), stability=torch.rand(1).item())\n",
        "    edges = [(\"MOF-5\", \"UiO-66\"), (\"MOF-5\", \"HKUST-1\"), (\"HKUST-1\", \"MIL-101\"), (\"UiO-66\", \"ZIF-8\")]\n",
        "    G.add_edges_from(edges)\n",
        "    return G\n",
        "\n",
        "def graph_to_pyg(G):\n",
        "    node_mapping = {node: i for i, node in enumerate(G.nodes)}\n",
        "    edge_index = torch.tensor([[node_mapping[u], node_mapping[v]] for u, v in G.edges], dtype=torch.long).t().contiguous()\n",
        "    features = torch.tensor([[G.nodes[node][\"adsorption\"], G.nodes[node][\"stability\"]] for node in G.nodes], dtype=torch.float)\n",
        "    return Data(x=features, edge_index=edge_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmsGzVpe8qkz"
      },
      "outputs": [],
      "source": [
        "class MOFGraphGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(MOFGraphGNN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "def train_gnn(data):\n",
        "    model = MOFGraphGNN(in_channels=2, hidden_channels=16, out_channels=4)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "    for epoch in range(200):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = loss_fn(out, data.x)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return model, out\n",
        "\n",
        "G = create_mof_networkx()\n",
        "data = graph_to_pyg(G)\n",
        "model, embeddings = train_gnn(data)\n",
        "print(\"✅ GNN Training Complete! Extracted Embeddings:\", embeddings.detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGKiQe9t8qkz"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
        "\n",
        "def llm_mof_insights(embeddings, mof_names):\n",
        "    insights = {}\n",
        "    for i, mof in enumerate(mof_names):\n",
        "        embedding_str = \", \".join([f\"{v:.4f}\" for v in embeddings[i].tolist()])\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"user\", \"content\": f\"Insights on {mof} with embedding {embedding_str}\"}]\n",
        "        )\n",
        "        insights[mof] = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    return insights\n",
        "\n",
        "mof_names = list(G.nodes)\n",
        "insights = llm_mof_insights(embeddings.detach().numpy(), mof_names)\n",
        "print(insights)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}